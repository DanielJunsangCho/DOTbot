# DOTbot - Unified Web Scraping and AI Behavior Analysis

DOTbot is a comprehensive web scraping and analysis system that combines general-purpose data extraction with specialized AI behavior detection capabilities. It integrates two previously separate systems into a unified, powerful platform.

## ğŸŒŸ Features

### Core Capabilities
- **Unified Web Scraping**: Extract structured data from any website
- **AI Behavior Analysis**: Detect and analyze concerning AI behaviors in content
- **Adaptive Scraping**: Automatically selects optimal scraping strategy (HTTP or browser-based)
- **Multiple Export Formats**: CSV, JSON, database storage
- **Quality Evaluation**: Built-in evaluation and metrics for data quality
- **Batch Processing**: Handle multiple URLs efficiently

### Advanced Features
- **LangGraph Workflows**: Sophisticated processing pipelines
- **Browser Automation**: Handle JavaScript-heavy and dynamic sites
- **Intelligent Routing**: Auto-select scraping method based on URL characteristics
- **Comprehensive Evaluation**: Multiple evaluation metrics and quality assessment
- **Session Management**: Track operations and maintain state

## ğŸ—ï¸ Architecture

```
DOTbot/
â”œâ”€â”€ core/                    # Shared infrastructure
â”‚   â”œâ”€â”€ schemas.py          # Unified data models
â”‚   â”œâ”€â”€ config.py           # Configuration management
â”‚   â””â”€â”€ storage.py          # Storage interfaces
â”‚
â”œâ”€â”€ scraping/               # Scraping capabilities
â”‚   â”œâ”€â”€ basic_scraper.py    # HTTP-based scraping
â”‚   â”œâ”€â”€ browser_scraper.py  # Browser automation
â”‚   â”œâ”€â”€ scraper_factory.py  # Scraper selection
â”‚   â””â”€â”€ tools/              # Extraction utilities
â”‚
â”œâ”€â”€ processing/             # Data processing
â”‚   â”œâ”€â”€ pipeline.py         # Processing workflows
â”‚   â”œâ”€â”€ classifiers.py      # Content classification
â”‚   â””â”€â”€ exporters.py        # Export utilities
â”‚
â”œâ”€â”€ workflows/              # LangGraph workflows
â”‚   â”œâ”€â”€ unified_workflow.py # Main orchestration
â”‚   â”œâ”€â”€ general_scrape.py   # General purpose workflow
â”‚   â””â”€â”€ ai_behavior_workflow.py # AI analysis workflow
â”‚
â”œâ”€â”€ evaluation/             # Quality assessment
â”‚   â”œâ”€â”€ evaluators.py       # Evaluation logic
â”‚   â”œâ”€â”€ metrics.py          # Metrics calculation
â”‚   â””â”€â”€ dataset_utils.py    # Dataset management
â”‚
â”œâ”€â”€ prompts/                # LLM prompts
â”‚   â”œâ”€â”€ agent_prompts.py    # Agent system prompts
â”‚   â”œâ”€â”€ classifier_prompts.py # Classification prompts
â”‚   â””â”€â”€ tool_prompts.py     # Tool descriptions
â”‚
â””â”€â”€ api/                    # User interfaces
    â”œâ”€â”€ main.py             # Main API
    â””â”€â”€ cli.py              # Command line interface
```

## ğŸš€ Quick Start

### Installation

```bash
# Clone the repository
git clone <repository-url>
cd DOTbot

# Install dependencies
pip install -r requirements.txt

# Set up environment variables
cp .env.example .env
# Edit .env with your API keys
```

### Environment Variables

Create a `.env` file with:

```env
OPENAI_API_KEY=your_openai_key_here
LANGSMITH_API_KEY=your_langsmith_key_here
LANGSMITH_PROJECT=DOTbot-Observatory
```

### Basic Usage

#### Command Line Interface

```bash
# General web scraping
python main.py scrape https://example.com/data --format csv

# AI behavior analysis
python main.py analyze https://lesswrong.com/posts/example "Find deceptive behaviors"

# Batch processing
python main.py batch --urls url1.com url2.com url3.com

# Show system information
python main.py info
```

#### Programmatic Usage

```python
import asyncio
from api.main import create_dotbot_instance

async def main():
    # Create DOTbot instance
    dotbot = create_dotbot_instance()
    
    # General web scraping
    result = await dotbot.extract_structured_data(
        url="https://example.com/data",
        scrape_mode="auto",
        export_format="csv"
    )
    
    # AI behavior analysis  
    analysis = await dotbot.analyze_ai_behavior(
        url="https://lesswrong.com/posts/example",
        question="Find examples of reward gaming",
        categories=["Reward Gaming", "Deceptive Behaviour"]
    )
    
    print(f"Analysis complete: {analysis['success']}")

asyncio.run(main())
```

## ğŸ”§ Configuration

### Scraping Modes

- **`basic`**: HTTP requests with BeautifulSoup (fast, reliable)
- **`browser`**: Browser automation with Browser-Use (handles JS)
- **`auto`**: Automatically selects optimal mode based on URL

### AI Behavior Categories

DOTbot analyzes content for these concerning behaviors:

1. **Deceptive Behaviour**: Misleading or false information
2. **Reward Gaming**: Exploiting evaluation metrics
3. **Sycophancy**: Telling users what they want to hear
4. **Goal Misgeneralization**: Pursuing unintended objectives
5. **Unauthorized Access**: Attempting to bypass restrictions

### Export Formats

- **CSV**: Structured tabular data
- **JSON**: Hierarchical data with metadata
- **Database**: SQLite storage for large datasets

## ğŸ“Š Evaluation and Quality

DOTbot includes comprehensive evaluation capabilities:

### General Scraping Metrics
- **Extraction Accuracy**: Completeness of data extraction
- **Structure Quality**: Consistency of extracted schema
- **Content Quality**: Meaningfulness of extracted content
- **Performance**: Speed and success rates

### AI Behavior Analysis Metrics
- **Detection Recall**: Coverage of concerning behaviors
- **Classification Precision**: Accuracy of behavior categorization
- **Semantic Fidelity**: Preservation of original meaning
- **Coverage**: Breadth of content analyzed

## ğŸ”„ Workflows

DOTbot uses LangGraph for sophisticated processing workflows:

### Unified Workflow
1. **Route Scraper**: Select optimal scraping method
2. **Perform Scraping**: Extract raw content
3. **Process Content**: Analyze and structure data
4. **Export Data**: Save in requested format
5. **Finalize**: Complete workflow and report results

### AI Behavior Workflow
1. **Initialize Analysis**: Set up behavior detection
2. **Scrape Content**: Extract relevant content
3. **Analyze Behavior**: Classify concerning behaviors
4. **Generate Reports**: Create detailed analysis reports
5. **Finalize Analysis**: Summarize findings

## ğŸ§ª Testing and Development

### Running Tests

```bash
# Install development dependencies
pip install pytest pytest-asyncio

# Run all tests
pytest

# Run specific test categories
pytest tests/test_scraping.py
pytest tests/test_processing.py
```

### Example Test

```python
import pytest
from api.main import create_dotbot_instance

@pytest.mark.asyncio
async def test_basic_scraping():
    dotbot = create_dotbot_instance()
    
    result = await dotbot.extract_structured_data(
        url="https://httpbin.org/json",
        scrape_mode="basic"
    )
    
    assert result["success"] == True
    assert result["export_path"] is not None
```

## ğŸ“š Advanced Usage

### Custom Scrapers

```python
from scraping.base_scraper import BaseScraper

class CustomScraper(BaseScraper):
    async def scrape_url(self, url: str, **kwargs):
        # Custom scraping logic
        pass
    
    def is_suitable_for_url(self, url: str) -> bool:
        return "custom-site.com" in url
```

### Custom Evaluation

```python
from evaluation.evaluators import BaseEvaluator

class CustomEvaluator(BaseEvaluator):
    async def evaluate(self, result, **kwargs):
        # Custom evaluation logic
        return EvaluationMetrics(custom_metric=0.95)
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature-name`
3. Make your changes
4. Add tests for new functionality
5. Run tests: `pytest`
6. Commit changes: `git commit -am 'Add feature'`
7. Push to branch: `git push origin feature-name`
8. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ› ï¸ Migration Notes

This unified system combines:
- **agent_workflow/**: General web scraping with LangGraph
- **src/**: AI behavior analysis with Browser-Use
- **evals/**: Evaluation framework with LangSmith

### Backward Compatibility

Legacy imports are supported through compatibility layers:

```python
# Old agent_workflow usage still works
from agent_workflow.src.basic_scraper import url_handler

# New unified usage
from scraping.tools.url_handler import url_handler
```

## ğŸ” Troubleshooting

### Common Issues

1. **Browser automation fails**: Install browser dependencies
   ```bash
   pip install playwright
   playwright install chromium
   ```

2. **LangSmith connection issues**: Check API key and project settings

3. **Import errors**: Ensure all dependencies are installed
   ```bash
   pip install -r requirements.txt
   ```

### Debug Mode

Enable verbose logging:

```bash
python main.py scrape <url> --verbose
```

Or programmatically:

```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

## ğŸ“ Support

- **Issues**: Create an issue on GitHub
- **Questions**: Check the documentation or create a discussion
- **Feature Requests**: Submit an enhancement issue

---

**DOTbot** - Unified Web Scraping and AI Behavior Analysis Tool